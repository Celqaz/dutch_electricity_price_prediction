{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef8b833-997d-4b67-b374-d1046343b4d3",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5a003ce-984b-4ff7-9ba0-2a2445842572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd14beb-2436-424e-a5cd-40d08e857a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "def load_data(dataset = 'df_19_24_cleaned'):\n",
    "    data = pd.read_pickle(f'../data/{dataset}.pkl') \n",
    "    print(data.info())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "843f42fa-bc8d-4a7d-a1f7-a3b4dff2c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "def data_scaler(data):\n",
    "    data_scaled = pd.DataFrame(scaler.fit_transform(data), columns=data.columns, index=data.index)\n",
    "    print('Data is scaled')\n",
    "    return data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d842cc-21b1-48d4-be55-39e3eec77e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train-Test Split (keeping all hourly data points in the last 7 days of each month for testing)\n",
    "def train_test_split_7(data):\n",
    "    test_indices = data.index.to_series().groupby([data.index.year, data.index.month]).apply(lambda x: x[-24*7:])\n",
    "    test_data = data.loc[test_indices]\n",
    "    train_data = data.drop(test_indices)\n",
    "    print(f'Shape of train_data: {train_data.shape}')\n",
    "    print(f'Shape of test_data: {test_data.shape}')\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31cba3-91ad-4c01-bcdf-e516f81ade5a",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4f4949f-c65e-494d-b0b2-a93761894052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length=24, target_column='price'):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data.iloc[i:i+seq_length].values)  # Include all features in X\n",
    "        y.append(data[target_column].iloc[i+seq_length])  # Target is still the original 'price'\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def create_sequences_2(data, seq_length=24, features = ['price']):\n",
    "    # features = ['price', 'wind_energy_generation', 'solar_energy_generation', 'total_load']\n",
    "    \n",
    "    # Convert to numpy array for easier slicing\n",
    "    data_array = data[features].values\n",
    "    \n",
    "    # Initialize lists for sequences and labels\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    # Create sequences\n",
    "    for i in range(len(data_array) - seq_length):\n",
    "        # Sequence of 24 time steps\n",
    "        sequences.append(data_array[i:i + seq_length])\n",
    "        \n",
    "        # The label is the price at the next time step after the sequence\n",
    "        labels.append(data_array[i + seq_length, 0])  # Assuming `price` is the first column\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    sequences = np.array(sequences)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return  sequences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f8c8ebc-d0f4-43ba-a155-d943698f9e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.2),  # Dropout to prevent overfitting\n",
    "        Dense(1)  # Output layer with a single neuron for regression\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19d8005-fd4c-4c7d-a2ab-a87954c4b094",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f17f36f-d9e7-4a5f-b6f3-3898eb2c8264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sMAPE function for evaluation\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef00cccf-eaa0-412e-9e45-a148692c0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_inverse(y_test_scaled, y_preds_scaled, X_test):\n",
    "    y_test_original = scaler.inverse_transform(\n",
    "        np.concatenate((y_test_scaled.reshape(-1, 1), X_test[:, -1, 1:]), axis=1))[:, 0]\n",
    "\n",
    "    y_preds_original = scaler.inverse_transform(\n",
    "        np.concatenate((y_preds_scaled, X_test[:, -1, 1:]), axis=1))[:, 0]\n",
    "\n",
    "    return y_test_original, y_preds_original\n",
    "    \n",
    "def scaler_inverse_2(y_test_scaled, y_preds_scaled, num_features = 1):\n",
    "    # Reshape predictions and true values for inverse transformation\n",
    "    y_preds_scaled = y_preds_scaled.reshape(-1, 1)\n",
    "    y_test_scaled = y_test_scaled.reshape(-1, 1)\n",
    "    \n",
    "    # Extend with zeros for other features to match scaler's input shape\n",
    "    # num_features = len(features)\n",
    "    zeros = np.zeros((len(y_preds_scaled), num_features - 1))\n",
    "    predictions_extended = np.concatenate([y_preds_scaled, zeros], axis=1)\n",
    "    # test\n",
    "    y_test_extended = np.concatenate([y_test, zeros], axis=1)\n",
    "    \n",
    "    # Inverse transform\n",
    "    y_preds_original = scaler.inverse_transform(predictions_extended)[:, 0]  # Only take price column\n",
    "    y_test_original = scaler.inverse_transform(y_test_extended)[:, 0]      \n",
    "\n",
    "    return y_test_original, y_preds_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f2682d0-f3c4-4ee1-a5bc-9ce2cd3f1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "def eva(y_test, y_pred, X_test):\n",
    "    \n",
    "    # Inverse scale predictions and actual values\n",
    "    y_pred_rescaled = scaler.inverse_transform(\n",
    "        np.concatenate((y_pred, X_test[:, -1, 1:]), axis=1)\n",
    "    )[:, 0]\n",
    "    y_test_rescaled = scaler.inverse_transform(\n",
    "        np.concatenate((y_test.reshape(-1, 1), X_test[:, -1, 1:]), axis=1)\n",
    "    )[:, 0]\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "                   \n",
    "    def smape(y_true, y_pred):\n",
    "        return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "    \n",
    "    \n",
    "    smape_value = smape(y_test_rescaled, y_pred_rescaled)\n",
    "    print(f\"Symmetric Mean Absolute Percentage Error (sMAPE): {smape_value:.2f}\")\n",
    "    return y_test_rescaled, y_pred_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c54c06d5-7a9f-477c-ae30-e8e31f53dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eva_s(y_test_rescaled, y_pred_rescaled):\n",
    "    \n",
    "    # Calculate MAE\n",
    "    mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "                   \n",
    "    def smape(y_true, y_pred):\n",
    "        return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "    \n",
    "    \n",
    "    smape_value = smape(y_test_rescaled, y_pred_rescaled)\n",
    "    print(f\"Symmetric Mean Absolute Percentage Error (sMAPE): {smape_value:.2f}\")\n",
    "\n",
    "    return mae, rmse, smape_value\n",
    "    # return y_test_rescaled, y_pred_rescaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2dd9c6-55d3-46ec-83a1-ac2aae17ed0b",
   "metadata": {},
   "source": [
    "# EWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9a1e194-b2c2-4811-965c-f9cf9103b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ewtpy\n",
    "\n",
    "# data: https://github.com/vrcarva/ewtpy/blob/master/ewtpy/ewtpy.py\n",
    "\n",
    "def ewt_decompose(data, K,  N = 5, log = 0, detect = \"locmax\", completion = 0, reg = 'average', lengthFilter = 10,sigmaFilter = 5):\n",
    "    ewt,  mfb ,boundaries = ewtpy.EWT1D(data, \n",
    "                                        N = K, \n",
    "                                        log = log, \n",
    "                                        detect = detect, \n",
    "                                        completion = completion, \n",
    "                                        reg = reg, \n",
    "                                        lengthFilter = lengthFilter,\n",
    "                                        sigmaFilter = sigmaFilter)\n",
    "    \n",
    "\n",
    "    combined_signal = np.sum(ewt, axis=1)\n",
    "    return combined_signal, ewt\n",
    "\n",
    "\n",
    "def plot_ewt(ewt, label = None ,start =None, end = None, ): \n",
    "    n = ewt.shape[1]\n",
    "    fig, axes = plt.subplots(n, 1, figsize=(12, 9))\n",
    "    for i in range(n):\n",
    "        axes[i].plot(ewt[start:end,i])\n",
    "        # axes[i].set_title(f'{name} EWT Component {i + 1}')\n",
    "    \n",
    "    # Set a shared ylabel for the entire plot\n",
    "    fig.text(-0.001, 0.5, label, va='center', rotation='vertical', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import ewtpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pywt import threshold\n",
    "\n",
    "# T = 1000\n",
    "# t = np.arange(1, T+1) / T\n",
    "# f = np.cos(2 * np.pi * 0.8 * t) + 2 * np.cos(2 * np.pi * 10 * t) + 0.8 * np.cos(2 * np.pi * 100 * t)\n",
    "\n",
    "def ewt_sureshrink_denoise(data, K, start=None, end=None, plot=False):\n",
    "    # Perform EWT decomposition\n",
    "    ewt, mfb, boundaries = ewtpy.EWT1D(data, N=K)\n",
    "    \n",
    "    # Apply SureShrink thresholding to each component\n",
    "    denoised_components = np.zeros_like(ewt)\n",
    "    for i in range(K):\n",
    "        component = ewt[:, i]\n",
    "        \n",
    "        # Calculate threshold based on the component's median absolute deviation (MAD)\n",
    "        sigma = np.median(np.abs(component - np.median(component))) / 0.6745\n",
    "        threshold_val = sigma * np.sqrt(2 * np.log(len(component)))\n",
    "        \n",
    "        # Apply soft thresholding to the component\n",
    "        denoised_components[:, i] = threshold(component, value=threshold_val, mode='soft')\n",
    "    \n",
    "    # Reconstruct the denoised signal by summing the denoised components\n",
    "    denoised_signal = np.sum(denoised_components, axis=1)\n",
    "    \n",
    "    # Plotting each component (optional)\n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(K + 1, 1, figsize=(12, 9))\n",
    "        for i in range(K):\n",
    "            axes[i].plot(denoised_components[start:end, i], label=f'Denoised EWT Component {i + 1}')\n",
    "            axes[i].legend()\n",
    "        axes[-1].plot(denoised_signal[start:end], label='Reconstructed Signal', color='black')\n",
    "        axes[-1].legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return denoised_signal, denoised_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a828b7-3623-4dba-ab50-8af3537d2279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ewt_decompose(signal, K):\n",
    "#     # Perform Fourier Transform\n",
    "#     fourier_transform = fft(signal)\n",
    "#     components = []\n",
    "#     freq_range = np.linspace(0, np.pi, K + 1)\n",
    "    \n",
    "#     # Define filters and extract components\n",
    "#     for i in range(K):\n",
    "#         filter_mask = np.zeros_like(fourier_transform)\n",
    "#         left_boundary = freq_range[i]\n",
    "#         right_boundary = freq_range[i + 1]\n",
    "        \n",
    "#         for j in range(len(fourier_transform)):\n",
    "#             frequency = j * np.pi / len(fourier_transform)\n",
    "#             if left_boundary <= frequency <= right_boundary:\n",
    "#                 filter_mask[j] = 1\n",
    "        \n",
    "#         # Apply filter and inverse FFT\n",
    "#         component_fft = fourier_transform * filter_mask\n",
    "#         component_ifft = ifft(component_fft).real  # Convert back to time domain\n",
    "#         components.append(component_ifft)\n",
    "    \n",
    "#     return np.array(components).T  # Shape: (t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f1c6b-e466-49bc-b24e-759e45f5e9fd",
   "metadata": {},
   "source": [
    "## Stat Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aeed9d0-fd70-4f40-9d7f-311891ec2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85f8527-a8c6-4cf7-8bc5-2b1db879a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(data):\n",
    "    adf_test = adfuller(data, regression='c')\n",
    "    print('ADF Statistic: {:.6f}\\np-value: {:.6f}\\n#Lags used: {}'\n",
    "          .format(adf_test[0], adf_test[1], adf_test[2]))\n",
    "    for key, value in adf_test[4].items():\n",
    "        print('Critical Value ({}): {:.6f}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b968e651-e0b3-4980-8390-c3cd0919c3eb",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2605ceb3-10da-4572-88ec-8c4852613730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "def plot_acf_pacf(data):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(10, 6))\n",
    "    plot_acf(data, lags=50, ax=ax1)\n",
    "    plot_pacf(data, lags=50, ax=ax2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc04090c-83a5-426e-ab7a-3f458756d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_preds(test, preds):\n",
    "    fig, ax = plt.subplots(figsize = (12,6))\n",
    "    # ax.plot(train['date'], train['data'], 'g-.', label='Train')\n",
    "    ax.plot(test, 'b-', label='Test')\n",
    "    ax.plot(preds, 'r--', label='Predicted')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Electricity Price')\n",
    "    # ax.axvspan(80, 83, color='#808080', alpha=0.2)\n",
    "    ax.legend(loc=2)\n",
    "    \n",
    "    \n",
    "    fig.autofmt_xdate()\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13036cd-55a9-49c9-9660-0f888a5be7db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
