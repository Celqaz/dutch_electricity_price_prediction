{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96e73ea-3a07-40b6-b453-2c64f8ff4a84",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd77863d-db9f-4a2d-9f38-e670b86077bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-03 11:33:59.526127: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Conv1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbfc8890-5392-44be-be72-abb6ddacdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('../data/data.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dc2990-cbc8-4fdd-bb81-0be38c2451a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 17520 entries, 2022-01-01 01:00:00 to 2024-01-01 00:00:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   solar          17520 non-null  int64  \n",
      " 1   wind_offshore  17520 non-null  int64  \n",
      " 2   wind_onshore   17520 non-null  int64  \n",
      " 3   total_load     17520 non-null  int64  \n",
      " 4   price          17520 non-null  float64\n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 821.2 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a99d5dc7-4739-4b79-a819-1f604c88d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for train-test split to retain all hourly data points in the last 7 days\n",
    "def train_test_split(data):\n",
    "    test_indices = data.index.to_series().groupby([data.index.year, data.index.month]).apply(lambda x: x[-24*7:])\n",
    "    test_data = data.loc[test_indices]\n",
    "    train_data = data.drop(test_indices)\n",
    "    return train_data, test_data\n",
    "\n",
    "# Perform the train-test split\n",
    "train_data, test_data = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3c911f0-d8b7-4369-a7de-b52f382ec405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create Sequences for Time Series Data\n",
    "def create_sequences(data, seq_length=24):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data.iloc[i:i+seq_length].values)\n",
    "        y.append(data['price'].iloc[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set sequence length (e.g., 24 for daily pattern)\n",
    "seq_length = 24\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f26146-b8af-48d3-ac34-7fb97b1ef539",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dba9ef-b408-4cfb-84bd-6cddf47ec7d0",
   "metadata": {},
   "source": [
    "### LTSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3075abd5-f9f8-4739-b25a-bf90345c60f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=input_shape),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a232bc-72e3-4860-98a6-84e06b6ef2a0",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5e70c7b-2d02-4afd-85a1-b92ff20291ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        Flatten(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32e1a4-7619-4106-8890-76d532ff2e78",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d46214b-344b-4bb3-bb7a-d0864d25a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(50, activation='relu', input_shape=input_shape),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39d0502-2d32-4160-a9d9-db313d82fef5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb2e17b0-523a-4192-96bf-611ed8ad480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input shape based on X_train\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cb22027-19f2-4306-b34c-8c27f3d5fbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libin/anaconda3/envs/th/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 4494.5557 - val_loss: 663.5211\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 886.7620 - val_loss: 192.8864\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 167.2725 - val_loss: 109.5191\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 112.1403 - val_loss: 113.9066\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 106.9638 - val_loss: 106.9782\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 96.5006 - val_loss: 100.8383\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 97.3009 - val_loss: 100.3692\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 98.7017 - val_loss: 93.9220\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 98.3386 - val_loss: 108.6389\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 93.3669 - val_loss: 107.4423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f97f8e03d00>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model = create_lstm_model(input_shape)\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41a0be87-95f6-4320-8cff-e28d4c69ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libin/anaconda3/envs/th/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 966.0616 - val_loss: 192.0738\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 222.0738 - val_loss: 179.1259\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 164.7022 - val_loss: 158.3282\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 135.3566 - val_loss: 88.5357\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 123.2223 - val_loss: 299.4613\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 138.3978 - val_loss: 94.4918\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 103.0097 - val_loss: 98.6727\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 105.7189 - val_loss: 103.5996\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74.7016 - val_loss: 59.8840\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - loss: 78.6274 - val_loss: 46.2326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f97f96e2d40>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train CNN\n",
    "cnn_model = create_cnn_model(input_shape)\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fdfb815-c5a6-4b74-a8cf-e12952b0cbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 338.8062 - val_loss: 68.4104\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 119.8285 - val_loss: 33.2506\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 50.1622 - val_loss: 56.8667\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 39.3918 - val_loss: 37.6336\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 38.5394 - val_loss: 28.3231\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 38.6326 - val_loss: 26.1029\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 35.7899 - val_loss: 20.4708\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 35.4328 - val_loss: 20.6410\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 31.9183 - val_loss: 27.5206\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 35.0059 - val_loss: 24.2268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f97f6d67370>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train GRU\n",
    "gru_model = create_gru_model(input_shape)\n",
    "gru_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51664b0e-e1de-48d9-bd0f-39831a170336",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b195f35-10dc-4b8e-8cd3-c32573d8e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sMAPE function\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbdb1326-ee91-425f-9f8c-fe76fe2436c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "lstm_preds = lstm_model.predict(X_test)\n",
    "cnn_preds = cnn_model.predict(X_test)\n",
    "gru_preds = gru_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37ce81bd-5345-48a6-b123-7f8cf579dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sMAPE\n",
    "lstm_smape = smape(y_test, lstm_preds)\n",
    "cnn_smape = smape(y_test, cnn_preds)\n",
    "gru_smape = smape(y_test, gru_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65e14aed-3121-4d1a-b37f-c0a8705bc149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM sMAPE: 55.82\n",
      "CNN sMAPE: 73.96\n",
      "GRU sMAPE: 66.48\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(f\"LSTM sMAPE: {lstm_smape:.2f}\")\n",
    "print(f\"CNN sMAPE: {cnn_smape:.2f}\")\n",
    "print(f\"GRU sMAPE: {gru_smape:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67e8f6-5fe1-49f7-8e63-5b8ffb4a2f5d",
   "metadata": {},
   "source": [
    "### new featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de906ab7-d002-471a-b685-21ad48be4013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Conv1D, Flatten\n",
    "\n",
    "# List of features to include\n",
    "features = ['price', 'wind_offshore', 'wind_onshore', 'solar', 'total_load']\n",
    "data = data[features]\n",
    "\n",
    "# Train-Test Split to include all hourly data points in the last 7 days of each month\n",
    "def train_test_split(data):\n",
    "    # Get indices for the last 7 days of each month\n",
    "    test_indices = data.index.to_series().groupby([data.index.year, data.index.month]).apply(lambda x: x[-24*7:])\n",
    "    test_data = data.loc[test_indices]\n",
    "    train_data = data.drop(test_indices)\n",
    "    return train_data, test_data\n",
    "\n",
    "# Perform the train-test split\n",
    "train_data, test_data = train_test_split(data)\n",
    "\n",
    "# Create Sequences for Time Series Data\n",
    "def create_sequences(data, seq_length=24):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data.iloc[i:i+seq_length].values)  # Include all features in X\n",
    "        y.append(data['price'].iloc[i+seq_length])  # Target is still electricity price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set sequence length (e.g., 24 for daily pattern)\n",
    "seq_length = 24\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56749129-4be8-40b1-84a8-5a5de365aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "\n",
    "# LSTM Model\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=input_shape),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "# CNN Model\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        Flatten(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "# GRU Model\n",
    "def create_gru_model(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(50, activation='relu', input_shape=input_shape),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1e52ac1-1704-43cf-91f1-daf870649f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input shape based on X_train\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2db90f8b-23a9-4c5e-a4a8-c062e34baf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libin/anaconda3/envs/th/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 22859.3828 - val_loss: 1163.5002\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 1390.3772 - val_loss: 160.6864\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 166.6660 - val_loss: 122.2878\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 103.6810 - val_loss: 93.5798\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 96.1220 - val_loss: 110.7205\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 100.1979 - val_loss: 86.9600\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 93.7845 - val_loss: 99.8928\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 95.7831 - val_loss: 95.3826\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 94.9677 - val_loss: 104.4508\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 96.8288 - val_loss: 107.1328\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libin/anaconda3/envs/th/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1215.7247 - val_loss: 216.2246\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 232.3160 - val_loss: 131.7258\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 166.3294 - val_loss: 127.8805\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 184.8764 - val_loss: 134.0547\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 162.4510 - val_loss: 78.5899\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 124.0528 - val_loss: 109.1081\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 112.7699 - val_loss: 212.4310\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 125.0139 - val_loss: 269.4325\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 113.2226 - val_loss: 56.0980\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 98.3578 - val_loss: 194.5726\n",
      "Epoch 1/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 438.6109 - val_loss: 97.1371\n",
      "Epoch 2/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 101.4844 - val_loss: 75.5110\n",
      "Epoch 3/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 81.8828 - val_loss: 70.6580\n",
      "Epoch 4/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 74.5163 - val_loss: 61.6399\n",
      "Epoch 5/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 65.4155 - val_loss: 54.2354\n",
      "Epoch 6/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 59.0644 - val_loss: 46.4185\n",
      "Epoch 7/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 52.0738 - val_loss: 41.8864\n",
      "Epoch 8/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 41.8462 - val_loss: 28.4551\n",
      "Epoch 9/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 36.4400 - val_loss: 30.2934\n",
      "Epoch 10/10\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 32.9612 - val_loss: 21.4023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f97e0971a80>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Models\n",
    "\n",
    "# Train LSTM\n",
    "lstm_model = create_lstm_model(input_shape)\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Train CNN\n",
    "cnn_model = create_cnn_model(input_shape)\n",
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Train GRU\n",
    "gru_model = create_gru_model(input_shape)\n",
    "gru_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "987c3924-52d6-450f-b9d5-4c29f27f8a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "LSTM sMAPE: 51.09\n",
      "CNN sMAPE: 68.38\n",
      "GRU sMAPE: 66.89\n"
     ]
    }
   ],
   "source": [
    "# Evaluate and Compare Models Using sMAPE\n",
    "\n",
    "# sMAPE function\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# Make predictions\n",
    "lstm_preds = lstm_model.predict(X_test)\n",
    "cnn_preds = cnn_model.predict(X_test)\n",
    "gru_preds = gru_model.predict(X_test)\n",
    "\n",
    "# Calculate sMAPE\n",
    "lstm_smape = smape(y_test, lstm_preds)\n",
    "cnn_smape = smape(y_test, cnn_preds)\n",
    "gru_smape = smape(y_test, gru_preds)\n",
    "\n",
    "# Display results\n",
    "print(f\"LSTM sMAPE: {lstm_smape:.2f}\")\n",
    "print(f\"CNN sMAPE: {cnn_smape:.2f}\")\n",
    "print(f\"GRU sMAPE: {gru_smape:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c3c898-ff30-4e82-9763-02e6edfa9499",
   "metadata": {},
   "source": [
    "### updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb9937b1-de3f-43ab-a660-7957c33067d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Conv1D, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Load dataset\n",
    "# data = pd.read_csv('your_data.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# List of initial features\n",
    "initial_features = ['price', 'wind_offshore', 'wind_onshore', 'solar', 'total_load']\n",
    "data = data[initial_features]\n",
    "\n",
    "# Feature Engineering: Create Lagged Features and Rolling Statistics\n",
    "def create_features(data):\n",
    "    for lag in [1, 7, 24]:  # Lagged features for last hour, last 7 hours, and last 24 hours\n",
    "        data[f'price_lag_{lag}'] = data['price'].shift(lag)\n",
    "    data['price_rolling_mean_24'] = data['price'].rolling(window=24).mean()\n",
    "    data['price_rolling_std_24'] = data['price'].rolling(window=24).std()\n",
    "    return data\n",
    "\n",
    "data = create_features(data)\n",
    "\n",
    "# Cyclic Encoding for Time-Related Features\n",
    "data['hour'] = data.index.hour\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "data['day_of_week_sin'] = np.sin(2 * np.pi * data['day_of_week'] / 7)\n",
    "data['day_of_week_cos'] = np.cos(2 * np.pi * data['day_of_week'] / 7)\n",
    "\n",
    "# Final list of features to include\n",
    "features = [\n",
    "    'price', 'wind_offshore', 'wind_onshore', 'solar', 'total_load', \n",
    "    'price_lag_1', 'price_lag_7', 'price_lag_24', 'price_rolling_mean_24', 'price_rolling_std_24',\n",
    "    'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos'\n",
    "]\n",
    "\n",
    "data = data[features].dropna()  # Drop rows with NaN values due to lagged features\n",
    "\n",
    "# 1. Train-Test Split\n",
    "def train_test_split(data):\n",
    "    test_indices = data.index.to_series().groupby([data.index.year, data.index.month]).apply(lambda x: x[-24*7:])\n",
    "    test_data = data.loc[test_indices]\n",
    "    train_data = data.drop(test_indices)\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = train_test_split(data)\n",
    "\n",
    "# 2. Create Sequences for Time Series Data\n",
    "def create_sequences(data, seq_length=24):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data.iloc[i:i+seq_length].values)  # Include all features in X\n",
    "        y.append(data['price'].iloc[i+seq_length])  # Target is electricity price\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 24\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "009d43d4-a7d2-48ba-9642-8f27acb9c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Define Models with Dropout Regularization\n",
    "\n",
    "# LSTM Model with Dropout\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mae')\n",
    "    return model\n",
    "\n",
    "# CNN Model with Dropout\n",
    "def create_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        Flatten(),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mae')\n",
    "    return model\n",
    "\n",
    "# GRU Model with Dropout\n",
    "def create_gru_model(input_shape):\n",
    "    model = Sequential([\n",
    "        GRU(64, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdf7ab9d-fc1a-4d4a-a2a8-505f0f12d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libin/anaconda3/envs/th/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/libin/anaconda3/envs/th/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 13634.7773 - val_loss: 1377.4082\n",
      "Epoch 2/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 3827.4893 - val_loss: 421.4138\n",
      "Epoch 3/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 242.5427 - val_loss: 276.7422\n",
      "Epoch 4/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 193.4321 - val_loss: 125.0931\n",
      "Epoch 5/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 120.3142 - val_loss: 103.6696\n",
      "Epoch 6/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 106.5658 - val_loss: 86.6853\n",
      "Epoch 7/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 115.9406 - val_loss: 110.6955\n",
      "Epoch 8/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 122.8999 - val_loss: 89.8546\n",
      "Epoch 9/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 105.5241 - val_loss: 106.7652\n",
      "Epoch 10/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 115.5681 - val_loss: 98.8850\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2410.3235 - val_loss: 94.8199\n",
      "Epoch 2/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 118.1590 - val_loss: 62.2029\n",
      "Epoch 3/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75.5340 - val_loss: 49.9986\n",
      "Epoch 4/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 63.7275 - val_loss: 64.1834\n",
      "Epoch 5/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 58.8314 - val_loss: 45.5329\n",
      "Epoch 6/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55.1995 - val_loss: 47.2726\n",
      "Epoch 7/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56.4924 - val_loss: 43.7409\n",
      "Epoch 8/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55.2473 - val_loss: 53.2215\n",
      "Epoch 9/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 56.0439 - val_loss: 42.8194\n",
      "Epoch 10/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 55.4886 - val_loss: 45.8249\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 1206.6548 - val_loss: 172.8338\n",
      "Epoch 2/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 212.9629 - val_loss: 74.3222\n",
      "Epoch 3/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 90.0979 - val_loss: 66.7575\n",
      "Epoch 4/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 84.6256 - val_loss: 65.7252\n",
      "Epoch 5/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 82.5822 - val_loss: 68.7465\n",
      "Epoch 6/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 83.4604 - val_loss: 82.6640\n",
      "Epoch 7/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 88.5933 - val_loss: 81.3998\n",
      "Epoch 8/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 86.7597 - val_loss: 80.9043\n",
      "Epoch 9/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 86.2344 - val_loss: 71.6355\n",
      "Epoch 10/10\n",
      "\u001b[1m378/378\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 84.1718 - val_loss: 85.3065\n",
      "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Set input shape based on X_train\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# 4. Train and Evaluate Models Using Cross-Validation\n",
    "\n",
    "# Initialize models\n",
    "lstm_model = create_lstm_model(input_shape)\n",
    "cnn_model = create_cnn_model(input_shape)\n",
    "gru_model = create_gru_model(input_shape)\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
    "    preds = model.predict(X_test)\n",
    "    return preds\n",
    "\n",
    "lstm_preds = train_and_evaluate(lstm_model, X_train, y_train, X_test, y_test)\n",
    "cnn_preds = train_and_evaluate(cnn_model, X_train, y_train, X_test, y_test)\n",
    "gru_preds = train_and_evaluate(gru_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3342b0a-5b60-4160-a661-1df0502566fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM sMAPE: 60.94\n",
      "CNN sMAPE: 60.20\n",
      "GRU sMAPE: 51.77\n"
     ]
    }
   ],
   "source": [
    "# 5. Calculate sMAPE\n",
    "\n",
    "# sMAPE function\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# Calculate sMAPE for each model\n",
    "lstm_smape = smape(y_test, lstm_preds)\n",
    "cnn_smape = smape(y_test, cnn_preds)\n",
    "gru_smape = smape(y_test, gru_preds)\n",
    "\n",
    "# Display results\n",
    "print(f\"LSTM sMAPE: {lstm_smape:.2f}\")\n",
    "print(f\"CNN sMAPE: {cnn_smape:.2f}\")\n",
    "print(f\"GRU sMAPE: {gru_smape:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b2acc-c841-448e-afda-b730a52b018f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "961d9676-1223-4a15-9b50-2e4f399336ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pywt\n",
    "import pandas as pd\n",
    "\n",
    "# Load original data\n",
    "data = pd.read_pickle('../data/data.pkl') \n",
    "# data = pd.read_csv('your_data.csv', parse_dates=['date'], index_col='date')\n",
    "features = ['price', 'wind_offshore', 'wind_onshore', 'solar', 'total_load']\n",
    "\n",
    "# Function to apply wavelet decomposition on a single time series\n",
    "def wavelet_decompose(series, wavelet='db1', level=3):\n",
    "    coeffs = pywt.wavedec(series, wavelet, level=level)\n",
    "    decomposed_data = pd.DataFrame(coeffs).T\n",
    "    decomposed_data.columns = [f'{series.name}_wavelet_{i}' for i in range(len(coeffs))]\n",
    "    return decomposed_data\n",
    "\n",
    "# Apply wavelet decomposition to each feature and store the decomposed components\n",
    "decomposed_features = []\n",
    "for feature in features:\n",
    "    decomposed = wavelet_decompose(data[feature], wavelet='db1', level=3)\n",
    "    decomposed.index = data.index[:len(decomposed)]  # Align indices with the original data\n",
    "    decomposed_features.append(decomposed)\n",
    "\n",
    "# Concatenate the decomposed features with the original data\n",
    "decomposed_data = pd.concat(decomposed_features, axis=1)\n",
    "data_with_wavelets = pd.concat([data, decomposed_data], axis=1)\n",
    "\n",
    "# Drop rows with NaN values (these appear due to wavelet decomposition)\n",
    "data_with_wavelets.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ea7dcf8-ef2d-4610-90ee-f41509d49402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17520, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b16cc5b-7e7c-439b-912d-59cd5c31123b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 20)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decomposed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48adac8d-90b5-4c9d-847a-e466928f999b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2190, 25)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_wavelets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e43cf0fb-9cca-4a05-af19-dc1655463fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libin/anaconda3/envs/th/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 38566.1289 - val_loss: 23464.2500\n",
      "Epoch 2/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20931.3125 - val_loss: 13564.5215\n",
      "Epoch 3/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 12160.7666 - val_loss: 13648.8916\n",
      "Epoch 4/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9905.8799 - val_loss: 8932.3047\n",
      "Epoch 5/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6592.6714 - val_loss: 4137.1592\n",
      "Epoch 6/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4248.2876 - val_loss: 3334.7336\n",
      "Epoch 7/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3031.0349 - val_loss: 1912.4199\n",
      "Epoch 8/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1969.6082 - val_loss: 1590.3502\n",
      "Epoch 9/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1425.4758 - val_loss: 1126.7745\n",
      "Epoch 10/10\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1256.4309 - val_loss: 1161.7040\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "LSTM sMAPE with Decomposed Features: 135.97\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Load the wavelet-decomposed dataset (data_with_wavelets should be created from the previous steps)\n",
    "# Make sure 'data_with_wavelets' includes the original and decomposed features\n",
    "# data_with_wavelets = pd.read_csv('data_with_wavelets.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# 1. Train-Test Split (keeping all hourly data points in the last 7 days of each month for testing)\n",
    "def train_test_split(data):\n",
    "    test_indices = data.index.to_series().groupby([data.index.year, data.index.month]).apply(lambda x: x[-24*7:])\n",
    "    test_data = data.loc[test_indices]\n",
    "    train_data = data.drop(test_indices)\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = train_test_split(data_with_wavelets)\n",
    "\n",
    "# 2. Create Sequences for LSTM Model\n",
    "# This function creates sequences of the specified length with all available features (original + decomposed)\n",
    "def create_sequences(data, seq_length=24, target_column='price'):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data.iloc[i:i+seq_length].values)  # All features are used in X\n",
    "        y.append(data[target_column].iloc[i+seq_length])  # Target is still the original 'price'\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Set the sequence length (e.g., 24 for daily patterns)\n",
    "seq_length = 24\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "# 3. Define the LSTM Model using Decomposed Features\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae')\n",
    "    return model\n",
    "\n",
    "# Set input shape based on X_train (accounting for all original + decomposed features)\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Initialize and train the model\n",
    "lstm_model = create_lstm_model(input_shape)\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# 4. Evaluate the Model\n",
    "# Define sMAPE function for evaluation\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "# Make predictions and calculate sMAPE\n",
    "lstm_preds = lstm_model.predict(X_test)\n",
    "lstm_smape = smape(y_test, lstm_preds)\n",
    "print(f\"LSTM sMAPE with Decomposed Features: {lstm_smape:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e3aa2-c96c-4253-ab74-71fec4b32104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
